{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPANION WORKBOOK\n",
    "\n",
    "# Model Training\n",
    "\n",
    "To make the most out of this program, we strongly recommend you to:\n",
    "1. First practice writing and implementing all of the code from Coding Section of the online module.\n",
    "2. Then, freely experiment with and explore any interesting or confusing concepts. Simply insert new code cells and then use the help of Google and official documentation.\n",
    "3. Finally, tackle all of the exercises at the end. They will help you tie everything together and **learn in context.**\n",
    "\n",
    "#### <span style=\"color:#555\">MODULE CODE SANDBOX</span>\n",
    "\n",
    "Use this space to practice writing and implementing all of the code from Coding Section of the online module. Insert new code cells as needed, and feel free to write notes to yourself in Markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Spending Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tx_price</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>584</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>58</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>39.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>101</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>379900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>618</td>\n",
       "      <td>33541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>127</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>83</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>340000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>73</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tx_price  beds  baths  sqft  lot_size  basement  restaurants  groceries  \\\n",
       "0    295850     1      1   584         0       0.0          107          9   \n",
       "1    216500     1      1   612         0       1.0          105         15   \n",
       "2    279900     1      1   615         0       0.0          183         13   \n",
       "3    379900     1      1   618     33541       0.0          198          9   \n",
       "4    340000     1      1   634         0       0.0          149          7   \n",
       "\n",
       "   nightlife  cafes  shopping  arts_entertainment  beauty_spas  active_life  \\\n",
       "0         30     19        89                   6           47           58   \n",
       "1          6     13        87                   2           26           14   \n",
       "2         31     30       101                  10           74           62   \n",
       "3         38     25       127                  11           72           83   \n",
       "4         22     20        83                  10           50           73   \n",
       "\n",
       "   median_age  married  college_grad  property_tax  insurance  median_school  \\\n",
       "0        33.0     65.0          84.0         234.0       81.0            9.0   \n",
       "1        39.0     73.0          69.0         169.0       51.0            3.0   \n",
       "2        28.0     15.0          86.0         216.0       74.0            8.0   \n",
       "3        36.0     25.0          91.0         265.0       92.0            9.0   \n",
       "4        37.0     20.0          75.0          88.0       30.0            9.0   \n",
       "\n",
       "   num_schools  two_and_two  property_age  during_recession  school_score  \\\n",
       "0          3.0            0             0                 1          27.0   \n",
       "1          3.0            0            41                 0           9.0   \n",
       "2          3.0            0            49                 1          24.0   \n",
       "3          3.0            0             5                 0          27.0   \n",
       "4          3.0            0            10                 0          27.0   \n",
       "\n",
       "   property_type_Apartment / Condo / Townhouse  property_type_Single-Family  \\\n",
       "0                                            1                            0   \n",
       "1                                            1                            0   \n",
       "2                                            1                            0   \n",
       "3                                            1                            0   \n",
       "4                                            1                            0   \n",
       "\n",
       "   exterior_walls_Brick  exterior_walls_Brick veneer  \\\n",
       "0                     0                            0   \n",
       "1                     1                            0   \n",
       "2                     0                            0   \n",
       "3                     0                            0   \n",
       "4                     1                            0   \n",
       "\n",
       "   exterior_walls_Combination  exterior_walls_Metal  exterior_walls_Missing  \\\n",
       "0                           0                     0                       0   \n",
       "1                           0                     0                       0   \n",
       "2                           0                     0                       0   \n",
       "3                           0                     0                       0   \n",
       "4                           0                     0                       0   \n",
       "\n",
       "   exterior_walls_Other  exterior_walls_Siding (Alum/Vinyl)  \\\n",
       "0                     0                                   0   \n",
       "1                     0                                   0   \n",
       "2                     0                                   0   \n",
       "3                     0                                   0   \n",
       "4                     0                                   0   \n",
       "\n",
       "   exterior_walls_Wood  roof_Asphalt  roof_Composition Shingle  roof_Missing  \\\n",
       "0                    1             0                         0             1   \n",
       "1                    0             0                         1             0   \n",
       "2                    1             0                         0             1   \n",
       "3                    1             0                         0             1   \n",
       "4                    0             0                         0             1   \n",
       "\n",
       "   roof_Other  roof_Shake Shingle  \n",
       "0           0                   0  \n",
       "1           0                   0  \n",
       "2           0                   0  \n",
       "3           0                   0  \n",
       "4           0                   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('analytical_base_table.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1863, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.tx_price\n",
    "X = df.drop('tx_price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 373 1490 373\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Preprocessing & Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.434228</td>\n",
       "      <td>2.579195</td>\n",
       "      <td>2322.785235</td>\n",
       "      <td>12746.659732</td>\n",
       "      <td>0.878523</td>\n",
       "      <td>39.495973</td>\n",
       "      <td>4.388591</td>\n",
       "      <td>5.004698</td>\n",
       "      <td>5.185906</td>\n",
       "      <td>39.561074</td>\n",
       "      <td>3.361745</td>\n",
       "      <td>22.909396</td>\n",
       "      <td>15.770470</td>\n",
       "      <td>38.508725</td>\n",
       "      <td>69.471141</td>\n",
       "      <td>65.012752</td>\n",
       "      <td>464.265772</td>\n",
       "      <td>139.610067</td>\n",
       "      <td>6.510067</td>\n",
       "      <td>2.779195</td>\n",
       "      <td>0.092617</td>\n",
       "      <td>24.343624</td>\n",
       "      <td>0.265772</td>\n",
       "      <td>17.940268</td>\n",
       "      <td>0.419463</td>\n",
       "      <td>0.580537</td>\n",
       "      <td>0.359732</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>0.059060</td>\n",
       "      <td>0.065772</td>\n",
       "      <td>0.119463</td>\n",
       "      <td>0.037584</td>\n",
       "      <td>0.268456</td>\n",
       "      <td>0.065772</td>\n",
       "      <td>0.073154</td>\n",
       "      <td>0.643624</td>\n",
       "      <td>0.189262</td>\n",
       "      <td>0.060403</td>\n",
       "      <td>0.033557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.072914</td>\n",
       "      <td>0.930476</td>\n",
       "      <td>1297.101677</td>\n",
       "      <td>34805.545024</td>\n",
       "      <td>0.326790</td>\n",
       "      <td>46.985862</td>\n",
       "      <td>4.498340</td>\n",
       "      <td>8.441995</td>\n",
       "      <td>7.442707</td>\n",
       "      <td>52.334853</td>\n",
       "      <td>4.693709</td>\n",
       "      <td>25.724463</td>\n",
       "      <td>17.999282</td>\n",
       "      <td>6.615223</td>\n",
       "      <td>19.865080</td>\n",
       "      <td>17.092542</td>\n",
       "      <td>227.249819</td>\n",
       "      <td>71.510905</td>\n",
       "      <td>1.975224</td>\n",
       "      <td>0.517235</td>\n",
       "      <td>0.289993</td>\n",
       "      <td>21.209025</td>\n",
       "      <td>0.441892</td>\n",
       "      <td>6.452059</td>\n",
       "      <td>0.493637</td>\n",
       "      <td>0.493637</td>\n",
       "      <td>0.480083</td>\n",
       "      <td>0.153601</td>\n",
       "      <td>0.235817</td>\n",
       "      <td>0.247966</td>\n",
       "      <td>0.324442</td>\n",
       "      <td>0.190252</td>\n",
       "      <td>0.443305</td>\n",
       "      <td>0.247966</td>\n",
       "      <td>0.260477</td>\n",
       "      <td>0.479089</td>\n",
       "      <td>0.391848</td>\n",
       "      <td>0.238311</td>\n",
       "      <td>0.180146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1351.000000</td>\n",
       "      <td>1542.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>53.250000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1913.500000</td>\n",
       "      <td>6183.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>426.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3014.750000</td>\n",
       "      <td>11761.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7842.000000</td>\n",
       "      <td>436471.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4508.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              beds        baths         sqft       lot_size     basement  \\\n",
       "count  1490.000000  1490.000000  1490.000000    1490.000000  1490.000000   \n",
       "mean      3.434228     2.579195  2322.785235   12746.659732     0.878523   \n",
       "std       1.072914     0.930476  1297.101677   34805.545024     0.326790   \n",
       "min       1.000000     1.000000   500.000000       0.000000     0.000000   \n",
       "25%       3.000000     2.000000  1351.000000    1542.000000     1.000000   \n",
       "50%       4.000000     3.000000  1913.500000    6183.000000     1.000000   \n",
       "75%       4.000000     3.000000  3014.750000   11761.000000     1.000000   \n",
       "max       5.000000     6.000000  7842.000000  436471.000000     1.000000   \n",
       "\n",
       "       restaurants    groceries    nightlife        cafes     shopping  \\\n",
       "count  1490.000000  1490.000000  1490.000000  1490.000000  1490.000000   \n",
       "mean     39.495973     4.388591     5.004698     5.185906    39.561074   \n",
       "std      46.985862     4.498340     8.441995     7.442707    52.334853   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       6.000000     1.000000     0.000000     0.000000     6.000000   \n",
       "50%      21.000000     3.000000     2.000000     3.000000    20.000000   \n",
       "75%      56.000000     7.000000     6.000000     6.000000    50.000000   \n",
       "max     266.000000    24.000000    53.000000    47.000000   340.000000   \n",
       "\n",
       "       arts_entertainment  beauty_spas  active_life   median_age      married  \\\n",
       "count         1490.000000  1490.000000  1490.000000  1490.000000  1490.000000   \n",
       "mean             3.361745    22.909396    15.770470    38.508725    69.471141   \n",
       "std              4.693709    25.724463    17.999282     6.615223    19.865080   \n",
       "min              0.000000     0.000000     0.000000    22.000000    11.000000   \n",
       "25%              0.000000     4.000000     4.000000    33.000000    59.000000   \n",
       "50%              2.000000    15.000000    10.000000    38.000000    74.000000   \n",
       "75%              5.000000    35.000000    21.000000    43.000000    84.000000   \n",
       "max             35.000000   177.000000    94.000000    69.000000   100.000000   \n",
       "\n",
       "       college_grad  property_tax    insurance  median_school  num_schools  \\\n",
       "count   1490.000000   1490.000000  1490.000000    1490.000000  1490.000000   \n",
       "mean      65.012752    464.265772   139.610067       6.510067     2.779195   \n",
       "std       17.092542    227.249819    71.510905       1.975224     0.517235   \n",
       "min        5.000000     88.000000    30.000000       1.000000     1.000000   \n",
       "25%       53.250000    321.000000    94.000000       5.000000     3.000000   \n",
       "50%       66.000000    426.000000   125.000000       7.000000     3.000000   \n",
       "75%       78.000000    572.000000   169.000000       8.000000     3.000000   \n",
       "max      100.000000   4508.000000  1374.000000      10.000000     4.000000   \n",
       "\n",
       "       two_and_two  property_age  during_recession  school_score  \\\n",
       "count  1490.000000   1490.000000       1490.000000   1490.000000   \n",
       "mean      0.092617     24.343624          0.265772     17.940268   \n",
       "std       0.289993     21.209025          0.441892      6.452059   \n",
       "min       0.000000      0.000000          0.000000      3.000000   \n",
       "25%       0.000000      6.000000          0.000000     12.000000   \n",
       "50%       0.000000     20.000000          0.000000     18.000000   \n",
       "75%       0.000000     38.000000          1.000000     24.000000   \n",
       "max       1.000000    114.000000          1.000000     30.000000   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                  1490.000000   \n",
       "mean                                      0.419463   \n",
       "std                                       0.493637   \n",
       "min                                       0.000000   \n",
       "25%                                       0.000000   \n",
       "50%                                       0.000000   \n",
       "75%                                       1.000000   \n",
       "max                                       1.000000   \n",
       "\n",
       "       property_type_Single-Family  exterior_walls_Brick  \\\n",
       "count                  1490.000000           1490.000000   \n",
       "mean                      0.580537              0.359732   \n",
       "std                       0.493637              0.480083   \n",
       "min                       0.000000              0.000000   \n",
       "25%                       0.000000              0.000000   \n",
       "50%                       1.000000              0.000000   \n",
       "75%                       1.000000              1.000000   \n",
       "max                       1.000000              1.000000   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                  1490.000000                 1490.000000   \n",
       "mean                      0.024161                    0.059060   \n",
       "std                       0.153601                    0.235817   \n",
       "min                       0.000000                    0.000000   \n",
       "25%                       0.000000                    0.000000   \n",
       "50%                       0.000000                    0.000000   \n",
       "75%                       0.000000                    0.000000   \n",
       "max                       1.000000                    1.000000   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count           1490.000000             1490.000000           1490.000000   \n",
       "mean               0.065772                0.119463              0.037584   \n",
       "std                0.247966                0.324442              0.190252   \n",
       "min                0.000000                0.000000              0.000000   \n",
       "25%                0.000000                0.000000              0.000000   \n",
       "50%                0.000000                0.000000              0.000000   \n",
       "75%                0.000000                0.000000              0.000000   \n",
       "max                1.000000                1.000000              1.000000   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                         1490.000000          1490.000000   1490.000000   \n",
       "mean                             0.268456             0.065772      0.073154   \n",
       "std                              0.443305             0.247966      0.260477   \n",
       "min                              0.000000             0.000000      0.000000   \n",
       "25%                              0.000000             0.000000      0.000000   \n",
       "50%                              0.000000             0.000000      0.000000   \n",
       "75%                              1.000000             0.000000      0.000000   \n",
       "max                              1.000000             1.000000      1.000000   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing   roof_Other  roof_Shake Shingle  \n",
       "count               1490.000000   1490.000000  1490.000000         1490.000000  \n",
       "mean                   0.643624      0.189262     0.060403            0.033557  \n",
       "std                    0.479089      0.391848     0.238311            0.180146  \n",
       "min                    0.000000      0.000000     0.000000            0.000000  \n",
       "25%                    0.000000      0.000000     0.000000            0.000000  \n",
       "50%                    1.000000      0.000000     0.000000            0.000000  \n",
       "75%                    1.000000      0.000000     0.000000            0.000000  \n",
       "max                    1.000000      1.000000     1.000000            1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = (X_train - X_train.mean())/X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.697</td>\n",
       "      <td>-1.405</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-2.496</td>\n",
       "      <td>-2.943</td>\n",
       "      <td>-3.511</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>-1.533</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>-3.440</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-2.316</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.735</td>\n",
       "      <td>-0.654</td>\n",
       "      <td>-0.833</td>\n",
       "      <td>-0.527</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.850</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.533</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.644</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.939</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459</td>\n",
       "      <td>3.676</td>\n",
       "      <td>4.255</td>\n",
       "      <td>12.174</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.821</td>\n",
       "      <td>4.360</td>\n",
       "      <td>5.685</td>\n",
       "      <td>5.618</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.741</td>\n",
       "      <td>5.990</td>\n",
       "      <td>4.346</td>\n",
       "      <td>4.609</td>\n",
       "      <td>1.537</td>\n",
       "      <td>2.047</td>\n",
       "      <td>17.794</td>\n",
       "      <td>17.262</td>\n",
       "      <td>1.767</td>\n",
       "      <td>2.360</td>\n",
       "      <td>3.129</td>\n",
       "      <td>4.227</td>\n",
       "      <td>1.662</td>\n",
       "      <td>1.869</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "      <td>1.334</td>\n",
       "      <td>6.353</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>5.059</td>\n",
       "      <td>1.650</td>\n",
       "      <td>3.768</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.069</td>\n",
       "      <td>3.943</td>\n",
       "      <td>5.365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beds    baths     sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 1490.000 1490.000 1490.000  1490.000  1490.000     1490.000   1490.000   \n",
       "mean    -0.000   -0.000    0.000     0.000     0.000        0.000      0.000   \n",
       "std      1.000    1.000    1.000     1.000     1.000        1.000      1.000   \n",
       "min     -2.269   -1.697   -1.405    -0.366    -2.688       -0.841     -0.976   \n",
       "25%     -0.405   -0.622   -0.749    -0.322     0.372       -0.713     -0.753   \n",
       "50%      0.527    0.452   -0.316    -0.189     0.372       -0.394     -0.309   \n",
       "75%      0.527    0.452    0.533    -0.028     0.372        0.351      0.581   \n",
       "max      1.459    3.676    4.255    12.174     0.372        4.821      4.360   \n",
       "\n",
       "       nightlife    cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count   1490.000 1490.000  1490.000            1490.000     1490.000   \n",
       "mean       0.000    0.000     0.000              -0.000        0.000   \n",
       "std        1.000    1.000     1.000               1.000        1.000   \n",
       "min       -0.593   -0.697    -0.756              -0.716       -0.891   \n",
       "25%       -0.593   -0.697    -0.641              -0.716       -0.735   \n",
       "50%       -0.356   -0.294    -0.374              -0.290       -0.307   \n",
       "75%        0.118    0.109     0.199               0.349        0.470   \n",
       "max        5.685    5.618     5.741               6.741        5.990   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count     1490.000    1490.000 1490.000      1490.000      1490.000   \n",
       "mean         0.000      -0.000   -0.000        -0.000         0.000   \n",
       "std          1.000       1.000    1.000         1.000         1.000   \n",
       "min         -0.876      -2.496   -2.943        -3.511        -1.656   \n",
       "25%         -0.654      -0.833   -0.527        -0.688        -0.630   \n",
       "50%         -0.321      -0.077    0.228         0.058        -0.168   \n",
       "75%          0.291       0.679    0.731         0.760         0.474   \n",
       "max          4.346       4.609    1.537         2.047        17.794   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  property_age  \\\n",
       "count   1490.000       1490.000     1490.000     1490.000      1490.000   \n",
       "mean      -0.000          0.000        0.000       -0.000        -0.000   \n",
       "std        1.000          1.000        1.000        1.000         1.000   \n",
       "min       -1.533         -2.790       -3.440       -0.319        -1.148   \n",
       "25%       -0.638         -0.765        0.427       -0.319        -0.865   \n",
       "50%       -0.204          0.248        0.427       -0.319        -0.205   \n",
       "75%        0.411          0.754        0.427       -0.319         0.644   \n",
       "max       17.262          1.767        2.360        3.129         4.227   \n",
       "\n",
       "       during_recession  school_score  \\\n",
       "count          1490.000      1490.000   \n",
       "mean             -0.000        -0.000   \n",
       "std               1.000         1.000   \n",
       "min              -0.601        -2.316   \n",
       "25%              -0.601        -0.921   \n",
       "50%              -0.601         0.009   \n",
       "75%               1.662         0.939   \n",
       "max               1.662         1.869   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                     1490.000   \n",
       "mean                                         0.000   \n",
       "std                                          1.000   \n",
       "min                                         -0.850   \n",
       "25%                                         -0.850   \n",
       "50%                                         -0.850   \n",
       "75%                                          1.176   \n",
       "max                                          1.176   \n",
       "\n",
       "       property_type_Single-Family  exterior_walls_Brick  \\\n",
       "count                     1490.000              1490.000   \n",
       "mean                        -0.000                 0.000   \n",
       "std                          1.000                 1.000   \n",
       "min                         -1.176                -0.749   \n",
       "25%                         -1.176                -0.749   \n",
       "50%                          0.850                -0.749   \n",
       "75%                          0.850                 1.334   \n",
       "max                          0.850                 1.334   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                     1490.000                    1490.000   \n",
       "mean                         0.000                       0.000   \n",
       "std                          1.000                       1.000   \n",
       "min                         -0.157                      -0.250   \n",
       "25%                         -0.157                      -0.250   \n",
       "50%                         -0.157                      -0.250   \n",
       "75%                         -0.157                      -0.250   \n",
       "max                          6.353                       3.990   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count              1490.000                1490.000              1490.000   \n",
       "mean                  0.000                   0.000                 0.000   \n",
       "std                   1.000                   1.000                 1.000   \n",
       "min                  -0.265                  -0.368                -0.198   \n",
       "25%                  -0.265                  -0.368                -0.198   \n",
       "50%                  -0.265                  -0.368                -0.198   \n",
       "75%                  -0.265                  -0.368                -0.198   \n",
       "max                   3.768                   2.714                 5.059   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                            1490.000             1490.000      1490.000   \n",
       "mean                                0.000               -0.000        -0.000   \n",
       "std                                 1.000                1.000         1.000   \n",
       "min                                -0.606               -0.265        -0.281   \n",
       "25%                                -0.606               -0.265        -0.281   \n",
       "50%                                -0.606               -0.265        -0.281   \n",
       "75%                                 1.650               -0.265        -0.281   \n",
       "max                                 1.650                3.768         3.558   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \n",
       "count                  1490.000      1490.000    1490.000            1490.000  \n",
       "mean                     -0.000         0.000      -0.000               0.000  \n",
       "std                       1.000         1.000       1.000               1.000  \n",
       "min                      -1.343        -0.483      -0.253              -0.186  \n",
       "25%                      -1.343        -0.483      -0.253              -0.186  \n",
       "50%                       0.744        -0.483      -0.253              -0.186  \n",
       "75%                       0.744        -0.483      -0.253              -0.186  \n",
       "max                       0.744         2.069       3.943               5.365  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = (X_test - X_train.mean())/X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>property_age</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>school_score</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "      <td>373.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.052</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.002</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1.078</td>\n",
       "      <td>1.121</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.019</td>\n",
       "      <td>0.922</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.908</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.895</td>\n",
       "      <td>1.068</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.987</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.018</td>\n",
       "      <td>1.150</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.051</td>\n",
       "      <td>0.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.697</td>\n",
       "      <td>-1.261</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-1.740</td>\n",
       "      <td>-2.843</td>\n",
       "      <td>-2.692</td>\n",
       "      <td>-1.396</td>\n",
       "      <td>-1.295</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>-3.440</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-2.316</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.804</td>\n",
       "      <td>-0.325</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.628</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.678</td>\n",
       "      <td>-0.703</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.850</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.306</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.691</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.939</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459</td>\n",
       "      <td>3.676</td>\n",
       "      <td>4.128</td>\n",
       "      <td>12.149</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.821</td>\n",
       "      <td>3.915</td>\n",
       "      <td>5.804</td>\n",
       "      <td>5.349</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.741</td>\n",
       "      <td>5.912</td>\n",
       "      <td>4.013</td>\n",
       "      <td>4.156</td>\n",
       "      <td>1.537</td>\n",
       "      <td>1.988</td>\n",
       "      <td>4.791</td>\n",
       "      <td>5.375</td>\n",
       "      <td>1.767</td>\n",
       "      <td>2.360</td>\n",
       "      <td>3.129</td>\n",
       "      <td>3.284</td>\n",
       "      <td>1.662</td>\n",
       "      <td>1.869</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "      <td>1.334</td>\n",
       "      <td>6.353</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>5.059</td>\n",
       "      <td>1.650</td>\n",
       "      <td>3.768</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.069</td>\n",
       "      <td>3.943</td>\n",
       "      <td>5.365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         beds   baths    sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 373.000 373.000 373.000   373.000   373.000      373.000    373.000   \n",
       "mean   -0.117  -0.081  -0.091    -0.032     0.011        0.091      0.141   \n",
       "std     0.959   0.989   1.002     1.034     0.988        1.004      0.996   \n",
       "min    -2.269  -1.697  -1.261    -0.366    -2.688       -0.841     -0.976   \n",
       "25%    -0.405  -0.622  -0.804    -0.325     0.372       -0.628     -0.753   \n",
       "50%    -0.405  -0.622  -0.387    -0.266     0.372       -0.287     -0.086   \n",
       "75%     0.527   0.452   0.306    -0.063     0.372        0.500      0.581   \n",
       "max     1.459   3.676   4.128    12.149     0.372        4.821      3.915   \n",
       "\n",
       "       nightlife   cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count    373.000 373.000   373.000             373.000      373.000   \n",
       "mean       0.057   0.109     0.132               0.048        0.108   \n",
       "std        1.034   1.078     1.121               1.013        1.019   \n",
       "min       -0.593  -0.697    -0.756              -0.716       -0.891   \n",
       "25%       -0.474  -0.562    -0.565              -0.716       -0.657   \n",
       "50%       -0.356  -0.294    -0.259              -0.290       -0.230   \n",
       "75%        0.118   0.244     0.333               0.349        0.587   \n",
       "max        5.804   5.349     5.741               6.741        5.912   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count      373.000     373.000  373.000       373.000       373.000   \n",
       "mean         0.035       0.072   -0.101         0.010        -0.064   \n",
       "std          0.922       1.021    0.949         0.945         0.890   \n",
       "min         -0.876      -1.740   -2.843        -2.692        -1.396   \n",
       "25%         -0.543      -0.682   -0.678        -0.703        -0.652   \n",
       "50%         -0.265      -0.077    0.077         0.058        -0.243   \n",
       "75%          0.346       0.679    0.631         0.760         0.267   \n",
       "max          4.013       4.156    1.537         1.988         4.791   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  property_age  \\\n",
       "count    373.000        373.000      373.000      373.000       373.000   \n",
       "mean      -0.055         -0.036        0.121        0.050         0.013   \n",
       "std        0.908          1.043        0.895        1.068         0.972   \n",
       "min       -1.295         -2.790       -3.440       -0.319        -1.148   \n",
       "25%       -0.666         -0.765        0.427       -0.319        -0.912   \n",
       "50%       -0.246          0.248        0.427       -0.319        -0.158   \n",
       "75%        0.271          0.754        0.427       -0.319         0.691   \n",
       "max        5.375          1.767        2.360        3.129         3.284   \n",
       "\n",
       "       during_recession  school_score  \\\n",
       "count           373.000       373.000   \n",
       "mean             -0.025         0.033   \n",
       "std               0.987         1.011   \n",
       "min              -0.601        -2.316   \n",
       "25%              -0.601        -0.921   \n",
       "50%              -0.601         0.009   \n",
       "75%               1.662         0.939   \n",
       "max               1.662         1.869   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                      373.000   \n",
       "mean                                         0.112   \n",
       "std                                          1.013   \n",
       "min                                         -0.850   \n",
       "25%                                         -0.850   \n",
       "50%                                         -0.850   \n",
       "75%                                          1.176   \n",
       "max                                          1.176   \n",
       "\n",
       "       property_type_Single-Family  exterior_walls_Brick  \\\n",
       "count                      373.000               373.000   \n",
       "mean                        -0.112                 0.066   \n",
       "std                          1.013                 1.018   \n",
       "min                         -1.176                -0.749   \n",
       "25%                         -1.176                -0.749   \n",
       "50%                          0.850                -0.749   \n",
       "75%                          0.850                 1.334   \n",
       "max                          0.850                 1.334   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                      373.000                     373.000   \n",
       "mean                         0.052                      -0.046   \n",
       "std                          1.150                       0.910   \n",
       "min                         -0.157                      -0.250   \n",
       "25%                         -0.157                      -0.250   \n",
       "50%                         -0.157                      -0.250   \n",
       "75%                         -0.157                      -0.250   \n",
       "max                          6.353                       3.990   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count               373.000                 373.000               373.000   \n",
       "mean                 -0.027                  -0.005                -0.043   \n",
       "std                   0.951                   0.996                 0.890   \n",
       "min                  -0.265                  -0.368                -0.198   \n",
       "25%                  -0.265                  -0.368                -0.198   \n",
       "50%                  -0.265                  -0.368                -0.198   \n",
       "75%                  -0.265                  -0.368                -0.198   \n",
       "max                   3.768                   2.714                 5.059   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                             373.000              373.000       373.000   \n",
       "mean                               -0.025               -0.006        -0.003   \n",
       "std                                 0.988                0.991         0.996   \n",
       "min                                -0.606               -0.265        -0.281   \n",
       "25%                                -0.606               -0.265        -0.281   \n",
       "50%                                -0.606               -0.265        -0.281   \n",
       "75%                                 1.650               -0.265        -0.281   \n",
       "max                                 1.650                3.768         3.558   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \n",
       "count                   373.000       373.000     373.000             373.000  \n",
       "mean                      0.011        -0.004       0.028              -0.052  \n",
       "std                       0.998         0.998       1.051               0.853  \n",
       "min                      -1.343        -0.483      -0.253              -0.186  \n",
       "25%                      -1.343        -0.483      -0.253              -0.186  \n",
       "50%                       0.744        -0.483      -0.253              -0.186  \n",
       "75%                       0.744        -0.483      -0.253              -0.186  \n",
       "max                       0.744         2.069       3.943               5.365  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lasso': make_pipeline(StandardScaler(), Lasso(random_state=1234)),\n",
    "    'ridge': make_pipeline(StandardScaler(), Ridge(random_state=1234))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines['enet'] = make_pipeline(StandardScaler(), ElasticNet(random_state=1234))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler', StandardScaler()),\n",
       "  ('elasticnet', ElasticNet(random_state=1234))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'elasticnet': ElasticNet(random_state=1234),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'elasticnet__alpha': 1.0,\n",
       " 'elasticnet__copy_X': True,\n",
       " 'elasticnet__fit_intercept': True,\n",
       " 'elasticnet__l1_ratio': 0.5,\n",
       " 'elasticnet__max_iter': 1000,\n",
       " 'elasticnet__normalize': False,\n",
       " 'elasticnet__positive': False,\n",
       " 'elasticnet__precompute': False,\n",
       " 'elasticnet__random_state': 1234,\n",
       " 'elasticnet__selection': 'cyclic',\n",
       " 'elasticnet__tol': 0.0001,\n",
       " 'elasticnet__warm_start': False}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['enet'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_hyperparameters = {\n",
    "    'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "}\n",
    "ridge_hyperparameters = {\n",
    "    'ridge__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_hyperparameters = {\n",
    "    'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "    'elasticnet__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'lasso': lasso_hyperparameters,\n",
    "    'ridge': ridge_hyperparameters,\n",
    "    'enet': enet_hyperparameters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(pipeline['lasso'], hyperparameters['lasso'], cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('lasso', Lasso(random_state=1234))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1,\n",
       "                                          5, 10]})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso  has been fitted\n",
      "ridge  has been fitted\n",
      "enet  has been fitted\n"
     ]
    }
   ],
   "source": [
    "fitted_model = {}\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    fitted_model[name] = model\n",
    "    print(name, ' has been fitted')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso 0.30862751652877196\n",
      "ridge 0.31661115859856537\n",
      "enet 0.34287462883286585\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_model.items():\n",
    "    print(name, model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('lasso', Lasso(random_state=1234))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1,\n",
       "                                          5, 10]})>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model['lasso'].get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = fitted_model['lasso'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:  0.40888624740715007\n",
      "MAE:  85035.54259559007\n"
     ]
    }
   ],
   "source": [
    "print('R2 Score: ', r2_score(y_test, pred))\n",
    "print('MAE: ' ,mean_absolute_error(y_test, pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#555\">EXERCISES</span>\n",
    "\n",
    "Complete each of the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.1 - Coding Section Checkpoint</span>\n",
    "\n",
    "Before moving on, it's imperative that you've been following along the online Coding Section of this module. Those are core to each module and often contain **mission-critical code**, which means that the following modules REQUIRE you to have run that code.\n",
    "\n",
    "#### A.) First, confirm that you've successfully separated the data into a training set and a test set.\n",
    "* How many observations are in the training set?\n",
    "* How many observations are in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 373 1490 373\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, display the Ridge regression pipeline object saved in the pipelines dictionary.\n",
    "* What steps are in the pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler', StandardScaler()),\n",
       "  ('ridge', Ridge(random_state=1234))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'ridge': Ridge(random_state=1234),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'ridge__alpha': 1.0,\n",
       " 'ridge__copy_X': True,\n",
       " 'ridge__fit_intercept': True,\n",
       " 'ridge__max_iter': None,\n",
       " 'ridge__normalize': False,\n",
       " 'ridge__random_state': 1234,\n",
       " 'ridge__solver': 'auto',\n",
       " 'ridge__tol': 0.001}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['ridge'].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=123, solver='auto', tol=0.001))]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Finally, display the <code>l1_ratio</code> hyperparameter values to try for your Elastic-Net algorithm.\n",
    "* **Tip:** Remember the naming convention within pipelines (need the named step first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.3, 0.5, 0.7, 0.9]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters['enet']['elasticnet__l1_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "[0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.2 - Sklearn's Standard Scaler</span>\n",
    "\n",
    "Whenever you preprocess your dataset, it's important to use the same **preprocessing parameters** on new data as you used on the training set. So if you standardize your dataset, you must also standardize the test set with the same means and standard deviations from the training set.\n",
    "\n",
    "#### A.) First, display the standardization parameters for the <code>beds</code> feature in the training set (<code>X_train</code>).\n",
    "* You'll need the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  3.434228187919463\n",
      "Std:  1.0729140858452646\n"
     ]
    }
   ],
   "source": [
    "print('Mean: ', X_train.beds.mean())\n",
    "print('Std: ', X_train.beds.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Mean: 3.434228187919463\n",
    "Standard Deviation: 1.0729140858452646\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, based on your parameters from part (A), manually standardize the first 5 observations from the <code>beds</code> feature in the TRAINING set. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689    1.459\n",
       "1531    0.527\n",
       "668    -0.405\n",
       "1740    1.459\n",
       "117    -1.337\n",
       "        ...  \n",
       "1228    0.527\n",
       "1077    0.527\n",
       "1318    0.527\n",
       "723    -0.405\n",
       "815    -0.405\n",
       "Name: beds, Length: 1490, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.beds - X_train.beds.mean())/X_train.beds.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "1689    1.459\n",
    "1531    0.527\n",
    "668    -0.405\n",
    "1740    1.459\n",
    "117    -1.337\n",
    "Name: beds, dtype: float64\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Next, based on your parameters from part (A), manually standardize the first 5 observations from the <code>beds</code> feature in the TEST set. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266    -1.337\n",
       "790    -0.405\n",
       "222    -1.337\n",
       "220    -1.337\n",
       "920    -0.405\n",
       "        ...  \n",
       "632    -0.405\n",
       "1557    0.527\n",
       "214    -1.337\n",
       "1488    0.527\n",
       "1140    0.527\n",
       "Name: beds, Length: 373, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test.beds - X_train.beds.mean())/X_train.beds.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "266   -1.337\n",
    "790   -0.405\n",
    "222   -1.337\n",
    "220   -1.337\n",
    "920   -0.405\n",
    "Name: beds, dtype: float64\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Scikit-Learn's <code>StandardScaler()</code> class allows you to save those preprocessing parameters learned from the training set.\n",
    "1. First, initialize and instance of the scaler class.\n",
    "\n",
    "<pre style=\"color:steelblue\">\n",
    "scaler = StandardScaler()\n",
    "</pre>\n",
    "\n",
    "2. Then, call the <code>.fit()</code> while passing in the **entire** training set (all of the features, not just beds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.) Now you can display the preprocessing parameters directly from the <code>scaler</code> object.\n",
    "* It will save the means from all features as an array in <code>.mean_</code>.\n",
    "* It will save the standard deviations from all features as an array in <code>.scale_</code>.\n",
    "* **Tip:** The <code>beds</code> feature should be the first one.\n",
    "* Check for yourself that the preprocessing parameters are the same as the ones you found in part (A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.434228187919463 1.0725539871320342\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_[0], scaler.scale_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Mean: 3.434228187919463\n",
    "Standard Deviation: 1.0725539871320342\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.) Next, use the <code>scaler</code> object to <code>.transform()</code> your test set and save it as <code>X_test_new</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when you use <code>scaler</code> to transform a dataset, it returns a NumPy array and NOT a Pandas DataFrame.\n",
    "\n",
    "#### G.) Confirm this for yourself. Display the class and shape of <code>X_test_new</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(373, 39)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test_new))\n",
    "print(X_test_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "&lt;class 'numpy.ndarray'&gt;\n",
    "(373, 39)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H.) Finally, display the first 5 transformed values for the <code>beds</code> feature.\n",
    "* Because <code>X_test_new</code> is a NumPy array, you won't be able to just call <code>.beds</code> like with Pandas DataFrames. If you try that, you'll get the error:\n",
    "\n",
    "<pre>\n",
    "<span style=\"color:crimson\">AttributeError:</span> 'numpy.ndarray' object has no attribute 'beds'\n",
    "</pre>\n",
    "\n",
    "* Instead, you'll need to index the NumPy array to get the **first 5 rows** from the **first column**. (This is just meant as a refresher and a bit of practice.)\n",
    "* Confirm that the values are the same as the ones you found in part (C) manually. Note that the rounding/precision may be slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.33720839, -0.40485439, -1.33720839, -1.33720839, -0.40485439])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new[:5,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "[-1.33720839 -0.40485439 -1.33720839 -1.33720839 -0.40485439]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.3 - Tree Pipelines</span>\n",
    "\n",
    "In the Coding Section, we created a pipeline dictionary with model pipelines for Lasso, Ridge, and Elastic-Net regressions. In this exercise, let's add pipelines for tree ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.) Add pipelines for <code style=\"color:SteelBlue\">RandomForestRegressor</code> and <code style=\"color:SteelBlue\">GradientBoostingRegressor</code> to your pipeline dictionary.\n",
    "* Name them <code style=\"color:crimson\">'rf'</code> for random forest and <code style=\"color:crimson\">'gb'</code> for gradient boosted tree.\n",
    "* Both pipelines should standardize the data first.\n",
    "* For both, set <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">123</span></code> to ensure replicable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines['rf'] = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=1234))\n",
    "pipelines['gb'] = make_pipeline(StandardScaler(), GradientBoostingRegressor(random_state=1234))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Just as a quick sanity check, display the pipeline object for your random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler', StandardScaler()),\n",
       "  ('randomforestregressor', RandomForestRegressor(random_state=1234))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'randomforestregressor': RandomForestRegressor(random_state=1234),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'randomforestregressor__bootstrap': True,\n",
       " 'randomforestregressor__ccp_alpha': 0.0,\n",
       " 'randomforestregressor__criterion': 'mse',\n",
       " 'randomforestregressor__max_depth': None,\n",
       " 'randomforestregressor__max_features': 'auto',\n",
       " 'randomforestregressor__max_leaf_nodes': None,\n",
       " 'randomforestregressor__max_samples': None,\n",
       " 'randomforestregressor__min_impurity_decrease': 0.0,\n",
       " 'randomforestregressor__min_impurity_split': None,\n",
       " 'randomforestregressor__min_samples_leaf': 1,\n",
       " 'randomforestregressor__min_samples_split': 2,\n",
       " 'randomforestregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'randomforestregressor__n_estimators': 100,\n",
       " 'randomforestregressor__n_jobs': None,\n",
       " 'randomforestregressor__oob_score': False,\n",
       " 'randomforestregressor__random_state': 1234,\n",
       " 'randomforestregressor__verbose': 0,\n",
       " 'randomforestregressor__warm_start': False}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['rf'].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) As another quick sanity check, display the class for the pipeline object for your random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pipelines['rf']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "&lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, let's check that all of the model pipelines are of the correct type. For each item in your <code>pipelines</code> dictionary, display its key and the class of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.pipeline.Pipeline'>\n",
      "ridge <class 'sklearn.pipeline.Pipeline'>\n",
      "enet <class 'sklearn.pipeline.Pipeline'>\n",
      "rf <class 'sklearn.pipeline.Pipeline'>\n",
      "gb <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "for name, pipeline in pipelines.items():\n",
    "    print(name, type(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "ridge &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "enet &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "rf &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "gb &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.4 - Hyperparameter Grids</span>\n",
    "\n",
    "In the Coding Section, we declared hyperparameter grids for our regularized regression algorithms: Lasso, Ridge, and Elastic-Net. Next, let's do the same for our tree ensembles.\n",
    "\n",
    "\n",
    "#### Let's start by declaring the hyperparameter grid for our random forest.\n",
    "\n",
    "The first one we'll tune is <code style=\"color:steelblue; font-weight:bold\">n_estimators</code>.\n",
    "* This is the number of decision trees to include in the random forest.\n",
    "* Usually, more is better.\n",
    "* The default value is 10, which is usually too few.\n",
    "* Let's try 100 and 200.\n",
    "\n",
    "The second one we'll tune is <code style=\"color:steelblue; font-weight:bold\">max_features</code>.\n",
    "* This controls the number of features each tree is allowed to choose from.\n",
    "* It's what allows your random forest to perform feature selection.\n",
    "* The default value is <code style=\"color:crimson\">'auto'</code>, which sets <code style=\"color:steelblue\">max_features = n_features</code>.\n",
    "* Let's also try <code style=\"color:crimson\">'sqrt'</code>, which sets <code style=\"color:steelblue\">max_features = sqrt(n_features)</code>\n",
    "* And <code style=\"color:crimson\">0.33</code>, which sets <code style=\"color:steelblue\">max_features = 0.33 * n_features</code>\n",
    "\n",
    "#### A.) Declare a hyperparameter grid for <code style=\"color:SteelBlue\">RandomForestRegressor</code>.\n",
    "* Name it <code style=\"color:steelblue\">rf_hyperparameters</code>\n",
    "\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__max_features'</span>: ['auto', 'sqrt', 0.33]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_hyperparameters = {\n",
    "    'randomforestregressor__n_estimators': [100, 200],\n",
    "    'randomforestregressor__max_features': ['auto', 'sqrt', 0.33]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler', StandardScaler()),\n",
       "  ('gradientboostingregressor', GradientBoostingRegressor(random_state=1234))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'gradientboostingregressor': GradientBoostingRegressor(random_state=1234),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'gradientboostingregressor__alpha': 0.9,\n",
       " 'gradientboostingregressor__ccp_alpha': 0.0,\n",
       " 'gradientboostingregressor__criterion': 'friedman_mse',\n",
       " 'gradientboostingregressor__init': None,\n",
       " 'gradientboostingregressor__learning_rate': 0.1,\n",
       " 'gradientboostingregressor__loss': 'ls',\n",
       " 'gradientboostingregressor__max_depth': 3,\n",
       " 'gradientboostingregressor__max_features': None,\n",
       " 'gradientboostingregressor__max_leaf_nodes': None,\n",
       " 'gradientboostingregressor__min_impurity_decrease': 0.0,\n",
       " 'gradientboostingregressor__min_impurity_split': None,\n",
       " 'gradientboostingregressor__min_samples_leaf': 1,\n",
       " 'gradientboostingregressor__min_samples_split': 2,\n",
       " 'gradientboostingregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'gradientboostingregressor__n_estimators': 100,\n",
       " 'gradientboostingregressor__n_iter_no_change': None,\n",
       " 'gradientboostingregressor__random_state': 1234,\n",
       " 'gradientboostingregressor__subsample': 1.0,\n",
       " 'gradientboostingregressor__tol': 0.0001,\n",
       " 'gradientboostingregressor__validation_fraction': 0.1,\n",
       " 'gradientboostingregressor__verbose': 0,\n",
       " 'gradientboostingregressor__warm_start': False}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['gb'].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's declare settings to try for our boosted tree.\n",
    "\n",
    "#### B.) Declare a hyperparameter grid for <code style=\"color:SteelBlue\">GradientBoostingRegressor</code>.\n",
    "* Name it <code style=\"color:steelblue\">gb_hyperparameters</code>.\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__learning_rate'</span>: [0.05, 0.1, 0.2]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__max_depth'</span>: [1, 3, 5]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_hyperparameters = {\n",
    "    'gradientboostingregressor__n_estimators': [100, 200],\n",
    "    'gradientboostingregressor__learning_rate': [0.005, 0.1, 0.2],\n",
    "    'gradientboostingregressor__max_depth': [1,3,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our hyperparameters declared, let's store them in a dictionary for ease of access.\n",
    "\n",
    "#### C.) Create a <code style=\"color:steelblue\">hyperparameters</code> dictionary.\n",
    "* Use the same keys as in the <code style=\"color:steelblue\">pipelines</code> dictionary.\n",
    "    * If you forgot what those keys were, you can insert a new code cell and call <code style=\"color:steelblue\">pipelines.keys()</code> for a reminder.\n",
    "* Set the values to the corresponding **hyperparameter grids** we've been declaring throughout this module.\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'rf'</span> : rf_hyperparameters</code>\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'lasso'</span> : lasso_hyperparameters</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters['rf'] = rf_hyperparameters\n",
    "hyperparameters['gb'] = gb_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, run this code to check that <code style=\"color:steelblue\">hyperparameters</code> is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet was found in hyperparameters, and it is a grid.\n",
      "gb was found in hyperparameters, and it is a grid.\n",
      "ridge was found in hyperparameters, and it is a grid.\n",
      "rf was found in hyperparameters, and it is a grid.\n",
      "lasso was found in hyperparameters, and it is a grid.\n"
     ]
    }
   ],
   "source": [
    "for key in ['enet', 'gb', 'ridge', 'rf', 'lasso']:\n",
    "    if key in hyperparameters:\n",
    "        if type(hyperparameters[key]) is dict:\n",
    "            print( key, 'was found in hyperparameters, and it is a grid.' )\n",
    "        else:\n",
    "            print( key, 'was found in hyperparameters, but it is not a grid.' )\n",
    "    else:\n",
    "        print( key, 'was not found in hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "enet was found in hyperparameters, and it is a grid.\n",
    "gb was found in hyperparameters, and it is a grid.\n",
    "ridge was found in hyperparameters, and it is a grid.\n",
    "rf was found in hyperparameters, and it is a grid.\n",
    "lasso was found in hyperparameters, and it is a grid.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.5 - Model Dictionaries</span>\n",
    "\n",
    "Similar to how we created dictionaries for our pipelines and hyperparameter grids, we can do the same for our fitted models. Obviously, there are other valid ways to organize your code and models, but this is a simple and practical way that does the job. By the end of the script, you'll have various dictionary objects that can each be accessed by the same consistent keys.\n",
    "\n",
    "#### A.) Create a dictionary of models named <code style=\"color:SteelBlue\">fitted_models</code> to store models that have been tuned using cross-validation.\n",
    "* The keys should be the same as those in the <code style=\"color:SteelBlue\">pipelines</code> and <code style=\"color:SteelBlue\">hyperparameters</code> dictionaries. \n",
    "* The values should be <code style=\"color:steelblue\">GridSearchCV</code> objects that have been fitted to <code style=\"color:steelblue\">X_train</code> and <code style=\"color:steelblue\">y_train</code>.\n",
    "* After fitting each model, print <code style=\"color:crimson\">'{name} has been fitted.'</code> just to track the progress.\n",
    "* **Tip:** We've started you off with some code.\n",
    "\n",
    "This step can take a few minutes, so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n",
      "ridge has been fitted.\n",
      "enet has been fitted.\n",
      "rf has been fitted.\n",
      "gb has been fitted.\n"
     ]
    }
   ],
   "source": [
    "fitted_models = {}\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    print(f'{name} has been fitted.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Check that the models are of the correct type. For each item in your <code>fitted_models</code> dictionary, display its key and the class of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "ridge <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "enet <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "rf <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "gb <class 'sklearn.model_selection._search.GridSearchCV'>\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(name, type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "ridge &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "enet &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "rf &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "gb &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Finally, run this code to check that the models have been fitted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n",
      "ridge has been fitted.\n",
      "enet has been fitted.\n",
      "rf has been fitted.\n",
      "gb has been fitted.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "for name, model in fitted_models.items():\n",
    "    try:\n",
    "        pred = model.predict(X_test)\n",
    "        print(name, 'has been fitted.')\n",
    "    except NotFittedError as e:\n",
    "        print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso has been fitted.\n",
    "ridge has been fitted.\n",
    "enet has been fitted.\n",
    "rf has been fitted.\n",
    "gb has been fitted.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.6 - Model Selection</span>\n",
    "\n",
    "In the Coding Section, we displayed performance metrics for a sample Lasso regression model. Now, let's do the same thing for all of our models, including our tree ensembles and then pick the final winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.) First, display the cross-validated training performance for each model in <code style=\"color:SteelBlue\">fitted_models</code> ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso 0.30862751652877196\n",
      "ridge 0.31661115859856537\n",
      "enet 0.34287462883286585\n",
      "rf 0.47904669461049176\n",
      "gb 0.48359445202000045\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(name, model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso 0.30862751105084013\n",
    "ridge 0.3166111585985649\n",
    "enet 0.34285741369864786\n",
    "rf 0.4801823564169308\n",
    "gb 0.48778099198016756\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, use a <code style=\"color:SteelBlue\">for</code> loop, print the performance of each model in <code style=\"color:SteelBlue\">fitted_models</code> on the test set.\n",
    "* Print both <code style=\"color:SteelBlue\">r2_score</code> and <code style=\"color:SteelBlue\">mean_absolute_error</code>.\n",
    "* Those functions each take two arguments:\n",
    "    * The actual values for your target variable (<code style=\"color:SteelBlue\">y_test</code>)\n",
    "    * Predicted values for your target variable\n",
    "* Label the output with the name of the algorithm. For example:\n",
    "\n",
    "<pre style=\"color:crimson\">\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.409313458932\n",
    "MAE: 84963.5598922\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso\n",
      "----------\n",
      "R^2:  0.40888624740715007\n",
      "MAE:  85035.54259559007\n",
      "ridge\n",
      "----------\n",
      "R^2:  0.40933964763297226\n",
      "MAE:  84978.03564808934\n",
      "enet\n",
      "----------\n",
      "R^2:  0.40524513747815083\n",
      "MAE:  86298.63724082337\n",
      "rf\n",
      "----------\n",
      "R^2:  0.5663882409045966\n",
      "MAE:  68779.34789544236\n",
      "gb\n",
      "----------\n",
      "R^2:  0.5284906692499404\n",
      "MAE:  70769.49851147253\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    pred = model.predict(X_test)\n",
    "    print(name)\n",
    "    print('----------')\n",
    "    print('R^2: ', r2_score(y_test, pred))\n",
    "    print('MAE: ', mean_absolute_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "\n",
    "<pre>\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.4088862476281637\n",
    "MAE: 85035.54256465772\n",
    "\n",
    "ridge\n",
    "--------\n",
    "R^2: 0.4093396476329718\n",
    "MAE: 84978.03564808934\n",
    "\n",
    "enet\n",
    "--------\n",
    "R^2: 0.4038573361696519\n",
    "MAE: 86529.0068234889\n",
    "\n",
    "rf\n",
    "--------\n",
    "R^2: 0.5712128842598444\n",
    "MAE: 67885.87587131368\n",
    "\n",
    "gb\n",
    "--------\n",
    "R^2: 0.5270040007880257\n",
    "MAE: 71245.11216404787\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Next, ask yourself these questions to pick the winning model:\n",
    "* Which model had the highest $R^2$ on the test set?\n",
    "* Which model had the lowest mean absolute error?\n",
    "* Are these two models the same one?\n",
    "* Did it also have the best holdout $R^2$ score from cross-validation?\n",
    "* Does it satisfy our project's win condition? (**Tip:** In the event of ambiguous results based on the previous questions, THIS should be your final deciding factor on whether a model is \"good enough.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, plot the performance of the winning model on the test set.\n",
    "* Plot a scatterplot with predicted transaction price on the x-axis and actual transaction price on the y-axis.\n",
    "* This last visual check is a nice way to confirm our model's performance.\n",
    "* Are the points scattered around the 45 degree diagonal (what does the 45 degree diagonal line represent)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gb\n",
      "----------\n",
      "R^2:  0.5663882409045966\n",
      "MAE:  68779.34789544236\n"
     ]
    }
   ],
   "source": [
    "pred = fitted_models['rf'].predict(X_test)\n",
    "print(name)\n",
    "print('----------')\n",
    "print('R^2: ', r2_score(y_test, pred))\n",
    "print('MAE: ', mean_absolute_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(pred, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<img src=\"data:image/png;base64,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&#10;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.7 - Saving Your Model</span>\n",
    "\n",
    "Great job, you've created a pretty kick-ass model for real-estate valuation. Now it's time to save your hard work.\n",
    "\n",
    "#### A.) First, display the class of your winning \"model\" in the <code>fitted_models</code> dictionary object.\n",
    "* Remember, you can access it with its corresponding key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestregressor',\n",
       "                 RandomForestRegressor(n_estimators=200, random_state=1234))])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_models['rf'].best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "sklearn.model_selection._search.GridSearchCV\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this is still the <code style=\"color:steelblue\">GridSearchCV</code> class. \n",
    "* You can actually directly save this object if you want, because it will use the winning model pipeline by default. \n",
    "* However, what we really care about is the actual winning model <code style=\"color:steelblue\">Pipeline</code>, right?\n",
    "\n",
    "#### B.) Confirm you can access the winning model pipeline. Display the class of the model pipeline.\n",
    "* **Tip:** You can use its <code style=\"color:steelblue\">best\\_estimator_</code> method to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "print(type(fitted_models['rf'].best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "sklearn.pipeline.Pipeline\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Display the winning pipeline object directly. What are the values of the winning values for our hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler', StandardScaler()),\n",
       "  ('randomforestregressor',\n",
       "   RandomForestRegressor(n_estimators=200, random_state=1234))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'randomforestregressor': RandomForestRegressor(n_estimators=200, random_state=1234),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'randomforestregressor__bootstrap': True,\n",
       " 'randomforestregressor__ccp_alpha': 0.0,\n",
       " 'randomforestregressor__criterion': 'mse',\n",
       " 'randomforestregressor__max_depth': None,\n",
       " 'randomforestregressor__max_features': 'auto',\n",
       " 'randomforestregressor__max_leaf_nodes': None,\n",
       " 'randomforestregressor__max_samples': None,\n",
       " 'randomforestregressor__min_impurity_decrease': 0.0,\n",
       " 'randomforestregressor__min_impurity_split': None,\n",
       " 'randomforestregressor__min_samples_leaf': 1,\n",
       " 'randomforestregressor__min_samples_split': 2,\n",
       " 'randomforestregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'randomforestregressor__n_estimators': 200,\n",
       " 'randomforestregressor__n_jobs': None,\n",
       " 'randomforestregressor__oob_score': False,\n",
       " 'randomforestregressor__random_state': 1234,\n",
       " 'randomforestregressor__verbose': 0,\n",
       " 'randomforestregressor__warm_start': False}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_models['rf'].best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winning values for our hyperparameters are:\n",
    "* <code style=\"color:steelblue\">n_estimators: <span style=\"color:crimson\">200</span></code>\n",
    "* <code style=\"color:steelblue\">max_features : <span style=\"color:crimson\">'auto'</span></code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, let's save the winning <code style=\"color:steelblue\">Pipeline</code> object object. To do so, we'll import a helpful package called <code style=\"color:steelblue\">pickle</code>, which saves Python objects to disk.\n",
    "* First, <code>import pickle</code>.\n",
    "* Then, use the following syntax to \"dump\" your model into a pickle file.\n",
    "\n",
    "<pre style=\"color:steelblue\">\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(<strong>insert answer to previous question here</strong>, f)\n",
    "</pre>\n",
    "* **Note:** We'll show you in the next project how to take this a step further and use the pickled model for various use cases. For now, we don't want to spread ourselves too thin over too many topics, so let's just save that final model and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(fitted_models['rf'].best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations... you've built and saved a successful model trained using machine learning!\n",
    "\n",
    "As a reminder, here are a few things you did in this module:\n",
    "* You split your dataset into separate training and test sets.\n",
    "* You set up preprocessing pipelines.\n",
    "* You tuned your models using cross-validation.\n",
    "* And you evaluated your models, selecting and saving the winner."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
